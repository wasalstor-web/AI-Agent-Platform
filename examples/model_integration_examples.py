"""
Example: Model Integration Usage
Ù…Ø«Ø§Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬

Demonstrates how to use the integrated AI models and agents.
"""

import asyncio
import logging
from dlplus.core import ModelManager, IntegrationBridge
from dlplus.agents import CodeGeneratorAgent, WebRetrievalAgent
from dlplus.config import ModelsConfig

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


async def example_basic_model_usage():
    """Example 1: Basic model inference"""
    logger.info("\n" + "="*70)
    logger.info("Example 1: Basic Model Inference | Ù…Ø«Ø§Ù„ 1: Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬")
    logger.info("="*70 + "\n")
    
    # Initialize model manager
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    
    # Load AraBERT for Arabic text understanding
    await manager.load_model('arabert')
    
    # Run inference
    result = await manager.inference(
        'arabert',
        'Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ø±ÙŠØ¯ ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ',
        {'temperature': 0.7}
    )
    
    logger.info(f"âœ… Model Output: {result['output']}")
    
    # Cleanup
    await manager.shutdown()


async def example_agent_with_models():
    """Example 2: Using agents with AI models"""
    logger.info("\n" + "="*70)
    logger.info("Example 2: Agent with AI Models | Ù…Ø«Ø§Ù„ 2: Ø§Ù„ÙˆÙƒÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒÙŠØ©")
    logger.info("="*70 + "\n")
    
    # Setup
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    
    # Create code generator agent
    agent = CodeGeneratorAgent()
    agent.set_model_manager(manager)
    
    # Load preferred models for code generation
    logger.info("ğŸ“¥ Loading models: DeepSeek, LLaMA 3...")
    await manager.preload_models(['deepseek', 'llama3'])
    
    # Execute code generation task in Arabic
    logger.info("\nğŸ¯ Task: Generate Python function for factorial calculation")
    result = await agent.run({
        'description': 'Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¶Ø±ÙˆØ¨ (factorial) Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµØ­ÙŠØ­Ø©',
        'language': 'python'
    })
    
    if result['success']:
        logger.info(f"\nâœ… Generated Code:\n{result['code']}")
    else:
        logger.info(f"\nâŒ Error: {result.get('error')}")
    
    # Cleanup
    await manager.shutdown()


async def example_web_retrieval_enhanced():
    """Example 3: Web retrieval with AI query enhancement"""
    logger.info("\n" + "="*70)
    logger.info("Example 3: Enhanced Web Search | Ù…Ø«Ø§Ù„ 3: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙŠØ¨")
    logger.info("="*70 + "\n")
    
    # Setup
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    
    # Create web retrieval agent
    agent = WebRetrievalAgent()
    agent.set_model_manager(manager)
    
    # Load Arabic models for query enhancement
    logger.info("ğŸ“¥ Loading Arabic models: AraBERT, CAMeLBERT...")
    await manager.preload_models(['arabert', 'camelbert'])
    
    # Execute search with AI-enhanced query
    logger.info("\nğŸ” Searching: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ")
    result = await agent.run({
        'query': 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ'
    })
    
    if result['success']:
        logger.info(f"\nğŸ“Š Original Query: {result['query']}")
        logger.info(f"âœ¨ Enhanced Query: {result.get('enhanced_query', 'N/A')}")
        logger.info(f"ğŸ“ˆ Found {result['count']} results")
    
    # Cleanup
    await manager.shutdown()


async def example_collaborative_execution():
    """Example 4: Collaborative execution with multiple models and agents"""
    logger.info("\n" + "="*70)
    logger.info("Example 4: Collaborative Execution | Ù…Ø«Ø§Ù„ 4: Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹Ø§ÙˆÙ†ÙŠ")
    logger.info("="*70 + "\n")
    
    # Setup
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    bridge = IntegrationBridge(manager)
    
    # Register agents
    code_agent = CodeGeneratorAgent()
    web_agent = WebRetrievalAgent()
    bridge.register_agent('code_gen', code_agent)
    bridge.register_agent('web_ret', web_agent)
    
    # Load models
    logger.info("ğŸ“¥ Loading models: AraBERT, DeepSeek...")
    await manager.preload_models(['arabert', 'deepseek'])
    
    # Execute collaborative task
    logger.info("\nğŸ¤ Collaborative Task: Search + Code Generation")
    result = await bridge.execute_collaborative(
        {'input': 'Ø§Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ÙØ±Ø² Ø«Ù… Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ Python Ù„Ù€ Quick Sort'},
        ['arabert', 'deepseek'],
        ['web_ret', 'code_gen']
    )
    
    if result['success']:
        logger.info("\nâœ… Collaborative Execution Complete")
        logger.info(f"ğŸ“Š Models used: {list(result['results']['models'].keys())}")
        logger.info(f"ğŸ¤– Agents used: {list(result['results']['agents'].keys())}")
        logger.info(f"â›“ï¸ Execution flow: {len(result['results']['collaboration_flow'])} steps")
    
    # Cleanup
    await manager.shutdown()


async def example_sequential_execution():
    """Example 5: Sequential execution chain"""
    logger.info("\n" + "="*70)
    logger.info("Example 5: Sequential Execution | Ù…Ø«Ø§Ù„ 5: Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØªØªØ§Ø¨Ø¹")
    logger.info("="*70 + "\n")
    
    # Setup
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    bridge = IntegrationBridge(manager)
    
    # Register agent
    code_agent = CodeGeneratorAgent()
    bridge.register_agent('code_gen', code_agent)
    
    # Load models
    await manager.preload_models(['arabert', 'deepseek'])
    
    # Execute sequential chain
    logger.info("â›“ï¸ Executing sequential chain:")
    logger.info("   1. AraBERT - Understand Arabic input")
    logger.info("   2. DeepSeek - Generate code logic")
    logger.info("   3. Code Agent - Format and validate\n")
    
    result = await bridge.execute_sequential(
        {'input': 'Ø§ÙƒØªØ¨ Ø¨Ø±Ù†Ø§Ù…Ø¬ Python Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø­ØªÙ‰ 100'},
        [
            {'type': 'model', 'id': 'arabert'},
            {'type': 'model', 'id': 'deepseek'},
            {'type': 'agent', 'id': 'code_gen'}
        ]
    )
    
    if result['success']:
        logger.info(f"\nâœ… Sequential Execution Complete")
        logger.info(f"ğŸ“Š Steps executed: {len(result['steps'])}")
        logger.info(f"ğŸ¯ Final output available")
    
    # Cleanup
    await manager.shutdown()


async def example_parallel_execution():
    """Example 6: Parallel execution with multiple models"""
    logger.info("\n" + "="*70)
    logger.info("Example 6: Parallel Execution | Ù…Ø«Ø§Ù„ 6: Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ")
    logger.info("="*70 + "\n")
    
    # Setup
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    bridge = IntegrationBridge(manager)
    
    # Load multiple Arabic models
    logger.info("ğŸ“¥ Loading Arabic models for parallel analysis...")
    await manager.preload_models(['arabert', 'camelbert', 'qwen_arabic'])
    
    # Execute parallel analysis
    logger.info("\nâš¡ Running parallel text analysis with 3 models...")
    result = await bridge.execute_parallel(
        {'input': 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ ÙŠØºÙŠØ± Ø§Ù„Ø¹Ø§Ù„Ù…'},
        [
            {'type': 'model', 'id': 'arabert'},
            {'type': 'model', 'id': 'camelbert'},
            {'type': 'model', 'id': 'qwen_arabic'}
        ]
    )
    
    if result['success']:
        logger.info("\nâœ… Parallel Execution Complete")
        logger.info(f"ğŸ“Š Results from {len(result['results'])} models")
        for key in result['results'].keys():
            logger.info(f"   - {key}")
    
    # Cleanup
    await manager.shutdown()


async def example_model_statistics():
    """Example 7: Model statistics and monitoring"""
    logger.info("\n" + "="*70)
    logger.info("Example 7: Model Statistics | Ù…Ø«Ø§Ù„ 7: Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
    logger.info("="*70 + "\n")
    
    # Setup
    models_config = ModelsConfig()
    manager = ModelManager(models_config)
    
    # Load models
    await manager.preload_models(['arabert', 'llama3', 'deepseek'])
    
    # Run some inferences
    logger.info("ğŸ”„ Running test inferences...")
    await manager.inference('arabert', 'Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ 1')
    await manager.inference('arabert', 'Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ 2')
    await manager.inference('llama3', 'test text')
    
    # Get statistics
    info = manager.get_all_models_info()
    
    logger.info(f"\nğŸ“Š Statistics:")
    logger.info(f"   Total loaded models: {info['total_loaded']}")
    logger.info(f"   Models by status:")
    for status, models in info['models_by_status'].items():
        if models:
            logger.info(f"      {status}: {len(models)} models")
    
    # Individual model stats
    logger.info("\nğŸ“ˆ AraBERT Statistics:")
    arabert_info = manager.get_model_info('arabert')
    if arabert_info:
        logger.info(f"   Inference count: {arabert_info['stats']['inference_count']}")
        logger.info(f"   Status: {arabert_info['status']}")
    
    # Cleanup
    await manager.shutdown()


async def main():
    """Run all examples"""
    logger.info("\n" + "="*70)
    logger.info("ğŸš€ AI Models and Agents Integration Examples")
    logger.info("Ø£Ù…Ø«Ù„Ø© ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠØ©")
    logger.info("="*70)
    
    examples = [
        ("Basic Model Usage", example_basic_model_usage),
        ("Agent with Models", example_agent_with_models),
        ("Enhanced Web Search", example_web_retrieval_enhanced),
        ("Collaborative Execution", example_collaborative_execution),
        ("Sequential Execution", example_sequential_execution),
        ("Parallel Execution", example_parallel_execution),
        ("Model Statistics", example_model_statistics),
    ]
    
    for i, (name, example_func) in enumerate(examples, 1):
        try:
            await example_func()
        except Exception as e:
            logger.error(f"\nâŒ Error in {name}: {e}")
    
    logger.info("\n" + "="*70)
    logger.info("âœ… All examples completed!")
    logger.info("="*70 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
