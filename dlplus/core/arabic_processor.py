"""
Arabic Language Processor
Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

Handles Arabic language understanding, analysis, and processing.
"""

import logging
import re
from typing import Dict, List, Any

logger = logging.getLogger(__name__)


class ArabicProcessor:
    """
    Arabic Language Processor
    Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰
    
    Processes Arabic text with grammatical, semantic, and contextual analysis.
    """
    
    def __init__(self):
        """Initialize the Arabic processor"""
        self.intent_keywords = self._load_intent_keywords()
        logger.info("ğŸ“– Arabic Processor initialized")
    
    def _load_intent_keywords(self) -> Dict[str, List[str]]:
        """Load intent detection keywords"""
        return {
            'code': ['ÙƒÙˆØ¯', 'Ø¨Ø±Ù…Ø¬Ø©', 'Ø§ÙƒØªØ¨', 'Ø³ÙƒØ±ÙŠØ¨Øª', 'Ø¨Ø±Ù†Ø§Ù…Ø¬', 'Ø¯Ø§Ù„Ø©', 'ÙˆØ¸ÙŠÙØ©'],
            'search': ['Ø§Ø¨Ø­Ø«', 'Ø¨Ø­Ø«', 'Ø§ÙŠØ¬Ø§Ø¯', 'Ø¥ÙŠØ¬Ø§Ø¯', 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'Ø¹Ù†', 'Ù…Ø§Ù‡Ùˆ', 'Ù…Ø§ Ù‡Ùˆ'],
            'translate': ['ØªØ±Ø¬Ù…', 'ØªØ±Ø¬Ù…Ø©', 'translate', 'translation'],
            'analyze': ['Ø­Ù„Ù„', 'ØªØ­Ù„ÙŠÙ„', 'Ø§ÙØ­Øµ', 'ÙØ­Øµ', 'analyze', 'analysis'],
            'execute': ['Ù†ÙØ°', 'ØªÙ†ÙÙŠØ°', 'Ø´ØºÙ„', 'ØªØ´ØºÙŠÙ„', 'execute', 'run'],
            'general': ['Ø§Ø´Ø±Ø­', 'Ø´Ø±Ø­', 'Ø³Ø§Ø¹Ø¯', 'Ù…Ø³Ø§Ø¹Ø¯Ø©', 'Ø£Ø®Ø¨Ø±', 'Ø§Ø®Ø¨Ø±']
        }
    
    async def analyze(self, text: str) -> Dict[str, Any]:
        """
        Analyze Arabic text
        
        Args:
            text: Arabic text to analyze
            
        Returns:
            Analysis dictionary with intent, entities, and metadata
        """
        try:
            # Normalize the text
            normalized = self._normalize_arabic(text)
            
            # Detect intent
            intent = self._detect_intent(normalized)
            
            # Extract entities
            entities = self._extract_entities(normalized)
            
            # Analyze sentiment
            sentiment = self._analyze_sentiment(normalized)
            
            # Grammar analysis (placeholder)
            grammar = self._analyze_grammar(normalized)
            
            return {
                'original': text,
                'normalized': normalized,
                'intent': intent,
                'entities': entities,
                'sentiment': sentiment,
                'grammar': grammar,
                'language': 'ar',
                'is_classical': self._is_classical_arabic(normalized)
            }
            
        except Exception as e:
            logger.error(f"Error analyzing Arabic text: {e}")
            return {
                'original': text,
                'intent': 'general',
                'entities': [],
                'error': str(e)
            }
    
    def _normalize_arabic(self, text: str) -> str:
        """Normalize Arabic text"""
        # Remove tashkeel (diacritics)
        text = re.sub(r'[\u064B-\u0652]', '', text)
        
        # Normalize alef
        text = re.sub(r'[Ø¥Ø£Ø¢Ø§]', 'Ø§', text)
        
        # Normalize teh marbuta
        text = re.sub(r'Ø©', 'Ù‡', text)
        
        # Normalize ya
        text = re.sub(r'Ù‰', 'ÙŠ', text)
        
        # Remove extra spaces
        text = ' '.join(text.split())
        
        return text.strip()
    
    def _detect_intent(self, text: str) -> str:
        """Detect user intent from text"""
        text_lower = text.lower()
        
        # Check each intent category
        for intent, keywords in self.intent_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    return intent
        
        # Default intent
        return 'general'
    
    def _extract_entities(self, text: str) -> List[Dict[str, str]]:
        """Extract named entities from text"""
        entities = []
        
        # Extract URLs
        url_pattern = r'https?://[^\s]+'
        urls = re.findall(url_pattern, text)
        for url in urls:
            entities.append({'type': 'url', 'value': url})
        
        # Extract file paths
        file_pattern = r'/[\w/.-]+|[A-Z]:\\[\w\\.-]+'
        files = re.findall(file_pattern, text)
        for file in files:
            entities.append({'type': 'file_path', 'value': file})
        
        # Extract numbers
        number_pattern = r'\d+'
        numbers = re.findall(number_pattern, text)
        for number in numbers:
            entities.append({'type': 'number', 'value': number})
        
        return entities
    
    def _analyze_sentiment(self, text: str) -> str:
        """Analyze sentiment of the text"""
        # Simple sentiment analysis
        positive_words = ['Ø¬ÙŠØ¯', 'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'Ø¬Ù…ÙŠÙ„', 'Ù…ÙÙŠØ¯', 'Ø´ÙƒØ±Ø§', 'Ø´ÙƒØ±Ø§']
        negative_words = ['Ø³ÙŠØ¦', 'Ø®Ø·Ø£', 'Ù…Ø´ÙƒÙ„Ù‡', 'Ù…Ø´ÙƒÙ„Ø©', 'ÙØ´Ù„', 'Ø®Ø·Ø§']
        
        text_lower = text.lower()
        
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
    
    def _analyze_grammar(self, text: str) -> Dict[str, Any]:
        """Analyze Arabic grammar (placeholder)"""
        # This would use NLP models in production
        return {
            'analyzed': True,
            'word_count': len(text.split()),
            'sentence_count': len(re.split(r'[.!?ØŸ]', text))
        }
    
    def _is_classical_arabic(self, text: str) -> bool:
        """Check if text is in classical Arabic"""
        # Simple heuristic: classical Arabic tends to have certain patterns
        # This is a placeholder - in production would use ML model
        classical_indicators = ['Ø¥Ù†', 'Ø£Ù†', 'Ù„Ù‚Ø¯', 'Ù‚Ø¯', 'Ù„ÙŠØ³', 'Ø¥Ø°Ø§', 'Ù„ÙƒÙ†']
        
        text_words = text.split()
        classical_word_count = sum(1 for word in classical_indicators if word in text_words)
        
        return classical_word_count > 0
    
    def generate_arabic_response(self, content: str, style: str = 'formal') -> str:
        """
        Generate proper Arabic response
        
        Args:
            content: Response content
            style: Response style ('formal', 'literary', 'analytical', 'commercial')
            
        Returns:
            Formatted Arabic response
        """
        # Add appropriate opening based on style
        openings = {
            'formal': 'ØªÙØ¶Ù„ØŒ ',
            'literary': 'Ø­Ø³Ù†Ø§Ù‹ØŒ ',
            'analytical': 'Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ ',
            'commercial': 'Ø¨ÙƒÙ„ Ø³Ø±ÙˆØ±ØŒ '
        }
        
        opening = openings.get(style, 'ØªÙØ¶Ù„ØŒ ')
        
        return f"{opening}{content}"
